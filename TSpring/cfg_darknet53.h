#pragma once
__declspec(selectany) char* cfg_darknet53 = "\n\
#This cfg file is generated by TSpring\n\
#https://github.com/springkim/TSpring\n\
#Darknet53(YOLOv3)\n\
[net]\n\
batch=%d\n\
subdivisions=%d\n\
width=%d\n\
height=%d\n\
channels=3\n\
momentum=0.9\n\
decay=0.0005\n\
angle=0\n\
saturation = 1.5\n\
exposure = 1.5\n\
hue=.1\n\
\n\
learning_rate=0.001\n\
burn_in=1000\n\
max_batches = %d\n\
policy=steps\n\
steps=40000,45000\n\
scales=.1,.1\n\
\n\
\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
filters=32\n\
size=3\n\
stride=1\n\
pad=1\n\
activation=leaky\n\
\n\
# Downsample\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
filters=64\n\
size=3\n\
stride=2\n\
pad=1\n\
activation=leaky\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
filters=32\n\
size=1\n\
stride=1\n\
pad=1\n\
activation=leaky\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
filters=64\n\
size=3\n\
stride=1\n\
pad=1\n\
activation=leaky\n\
\n\
[shortcut]\n\
from=-3\n\
activation=linear\n\
\n\
# Downsample\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
filters=128\n\
size=3\n\
stride=2\n\
pad=1\n\
activation=leaky\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
filters=64\n\
size=1\n\
stride=1\n\
pad=1\n\
activation=leaky\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
filters=128\n\
size=3\n\
stride=1\n\
pad=1\n\
activation=leaky\n\
\n\
[shortcut]\n\
from=-3\n\
activation=linear\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
filters=64\n\
size=1\n\
stride=1\n\
pad=1\n\
activation=leaky\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
filters=128\n\
size=3\n\
stride=1\n\
pad=1\n\
activation=leaky\n\
\n\
[shortcut]\n\
from=-3\n\
activation=linear\n\
\n\
# Downsample\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
filters=256\n\
size=3\n\
stride=2\n\
pad=1\n\
activation=leaky\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
filters=128\n\
size=1\n\
stride=1\n\
pad=1\n\
activation=leaky\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
filters=256\n\
size=3\n\
stride=1\n\
pad=1\n\
activation=leaky\n\
\n\
[shortcut]\n\
from=-3\n\
activation=linear\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
filters=128\n\
size=1\n\
stride=1\n\
pad=1\n\
activation=leaky\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
filters=256\n\
size=3\n\
stride=1\n\
pad=1\n\
activation=leaky\n\
\n\
[shortcut]\n\
from=-3\n\
activation=linear\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
filters=128\n\
size=1\n\
stride=1\n\
pad=1\n\
activation=leaky\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
filters=256\n\
size=3\n\
stride=1\n\
pad=1\n\
activation=leaky\n\
\n\
[shortcut]\n\
from=-3\n\
activation=linear\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
filters=128\n\
size=1\n\
stride=1\n\
pad=1\n\
activation=leaky\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
filters=256\n\
size=3\n\
stride=1\n\
pad=1\n\
activation=leaky\n\
\n\
[shortcut]\n\
from=-3\n\
activation=linear\n\
\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
filters=128\n\
size=1\n\
stride=1\n\
pad=1\n\
activation=leaky\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
filters=256\n\
size=3\n\
stride=1\n\
pad=1\n\
activation=leaky\n\
\n\
[shortcut]\n\
from=-3\n\
activation=linear\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
filters=128\n\
size=1\n\
stride=1\n\
pad=1\n\
activation=leaky\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
filters=256\n\
size=3\n\
stride=1\n\
pad=1\n\
activation=leaky\n\
\n\
[shortcut]\n\
from=-3\n\
activation=linear\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
filters=128\n\
size=1\n\
stride=1\n\
pad=1\n\
activation=leaky\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
filters=256\n\
size=3\n\
stride=1\n\
pad=1\n\
activation=leaky\n\
\n\
[shortcut]\n\
from=-3\n\
activation=linear\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
filters=128\n\
size=1\n\
stride=1\n\
pad=1\n\
activation=leaky\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
filters=256\n\
size=3\n\
stride=1\n\
pad=1\n\
activation=leaky\n\
\n\
[shortcut]\n\
from=-3\n\
activation=linear\n\
\n\
# Downsample\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
filters=512\n\
size=3\n\
stride=2\n\
pad=1\n\
activation=leaky\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
filters=256\n\
size=1\n\
stride=1\n\
pad=1\n\
activation=leaky\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
filters=512\n\
size=3\n\
stride=1\n\
pad=1\n\
activation=leaky\n\
\n\
[shortcut]\n\
from=-3\n\
activation=linear\n\
\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
filters=256\n\
size=1\n\
stride=1\n\
pad=1\n\
activation=leaky\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
filters=512\n\
size=3\n\
stride=1\n\
pad=1\n\
activation=leaky\n\
\n\
[shortcut]\n\
from=-3\n\
activation=linear\n\
\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
filters=256\n\
size=1\n\
stride=1\n\
pad=1\n\
activation=leaky\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
filters=512\n\
size=3\n\
stride=1\n\
pad=1\n\
activation=leaky\n\
\n\
[shortcut]\n\
from=-3\n\
activation=linear\n\
\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
filters=256\n\
size=1\n\
stride=1\n\
pad=1\n\
activation=leaky\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
filters=512\n\
size=3\n\
stride=1\n\
pad=1\n\
activation=leaky\n\
\n\
[shortcut]\n\
from=-3\n\
activation=linear\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
filters=256\n\
size=1\n\
stride=1\n\
pad=1\n\
activation=leaky\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
filters=512\n\
size=3\n\
stride=1\n\
pad=1\n\
activation=leaky\n\
\n\
[shortcut]\n\
from=-3\n\
activation=linear\n\
\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
filters=256\n\
size=1\n\
stride=1\n\
pad=1\n\
activation=leaky\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
filters=512\n\
size=3\n\
stride=1\n\
pad=1\n\
activation=leaky\n\
\n\
[shortcut]\n\
from=-3\n\
activation=linear\n\
\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
filters=256\n\
size=1\n\
stride=1\n\
pad=1\n\
activation=leaky\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
filters=512\n\
size=3\n\
stride=1\n\
pad=1\n\
activation=leaky\n\
\n\
[shortcut]\n\
from=-3\n\
activation=linear\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
filters=256\n\
size=1\n\
stride=1\n\
pad=1\n\
activation=leaky\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
filters=512\n\
size=3\n\
stride=1\n\
pad=1\n\
activation=leaky\n\
\n\
[shortcut]\n\
from=-3\n\
activation=linear\n\
\n\
# Downsample\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
filters=1024\n\
size=3\n\
stride=2\n\
pad=1\n\
activation=leaky\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
filters=512\n\
size=1\n\
stride=1\n\
pad=1\n\
activation=leaky\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
filters=1024\n\
size=3\n\
stride=1\n\
pad=1\n\
activation=leaky\n\
\n\
[shortcut]\n\
from=-3\n\
activation=linear\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
filters=512\n\
size=1\n\
stride=1\n\
pad=1\n\
activation=leaky\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
filters=1024\n\
size=3\n\
stride=1\n\
pad=1\n\
activation=leaky\n\
\n\
[shortcut]\n\
from=-3\n\
activation=linear\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
filters=512\n\
size=1\n\
stride=1\n\
pad=1\n\
activation=leaky\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
filters=1024\n\
size=3\n\
stride=1\n\
pad=1\n\
activation=leaky\n\
\n\
[shortcut]\n\
from=-3\n\
activation=linear\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
filters=512\n\
size=1\n\
stride=1\n\
pad=1\n\
activation=leaky\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
filters=1024\n\
size=3\n\
stride=1\n\
pad=1\n\
activation=leaky\n\
\n\
[shortcut]\n\
from=-3\n\
activation=linear\n\
\n\
######################\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
filters=512\n\
size=1\n\
stride=1\n\
pad=1\n\
activation=leaky\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
size=3\n\
stride=1\n\
pad=1\n\
filters=1024\n\
activation=leaky\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
filters=512\n\
size=1\n\
stride=1\n\
pad=1\n\
activation=leaky\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
size=3\n\
stride=1\n\
pad=1\n\
filters=1024\n\
activation=leaky\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
filters=512\n\
size=1\n\
stride=1\n\
pad=1\n\
activation=leaky\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
size=3\n\
stride=1\n\
pad=1\n\
filters=1024\n\
activation=leaky\n\
\n\
[convolutional]\n\
size=1\n\
stride=1\n\
pad=1\n\
filters=%d\n\
activation=linear\n\
\n\
[yolo]\n\
mask = %s\n\
anchors = %s\n\
classes=%d\n\
num=%d\n\
jitter=.3\n\
ignore_thresh = .5\n\
truth_thresh = 1\n\
random=%d\n\
\n\
[route]\n\
layers = -4\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
filters=256\n\
size=1\n\
stride=1\n\
pad=1\n\
activation=leaky\n\
\n\
[upsample]\n\
stride=2\n\
\n\
[route]\n\
layers = -1, 61\n\
\n\
\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
filters=256\n\
size=1\n\
stride=1\n\
pad=1\n\
activation=leaky\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
size=3\n\
stride=1\n\
pad=1\n\
filters=512\n\
activation=leaky\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
filters=256\n\
size=1\n\
stride=1\n\
pad=1\n\
activation=leaky\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
size=3\n\
stride=1\n\
pad=1\n\
filters=512\n\
activation=leaky\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
filters=256\n\
size=1\n\
stride=1\n\
pad=1\n\
activation=leaky\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
size=3\n\
stride=1\n\
pad=1\n\
filters=512\n\
activation=leaky\n\
\n\
[convolutional]\n\
size=1\n\
stride=1\n\
pad=1\n\
filters=%d\n\
activation=linear\n\
\n\
[yolo]\n\
mask = %s\n\
anchors = %s\n\
classes=%d\n\
num=%d\n\
jitter=.3\n\
ignore_thresh = .5\n\
truth_thresh = 1\n\
random=%d\n\
\n\
[route]\n\
layers = -4\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
filters=128\n\
size=1\n\
stride=1\n\
pad=1\n\
activation=leaky\n\
\n\
[upsample]\n\
stride=2\n\
\n\
[route]\n\
layers = -1, 36\n\
\n\
\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
filters=128\n\
size=1\n\
stride=1\n\
pad=1\n\
activation=leaky\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
size=3\n\
stride=1\n\
pad=1\n\
filters=256\n\
activation=leaky\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
filters=128\n\
size=1\n\
stride=1\n\
pad=1\n\
activation=leaky\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
size=3\n\
stride=1\n\
pad=1\n\
filters=256\n\
activation=leaky\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
filters=128\n\
size=1\n\
stride=1\n\
pad=1\n\
activation=leaky\n\
\n\
[convolutional]\n\
batch_normalize=1\n\
size=3\n\
stride=1\n\
pad=1\n\
filters=256\n\
activation=leaky\n\
\n\
[convolutional]\n\
size=1\n\
stride=1\n\
pad=1\n\
filters=%d\n\
activation=linear\n\
\n\
[yolo]\n\
mask = %s\n\
anchors = %s\n\
classes=%d\n\
num=%d\n\
jitter=.3\n\
ignore_thresh = .5\n\
truth_thresh = 1\n\
random=%d\n\
\n\
";